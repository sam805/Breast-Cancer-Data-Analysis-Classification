{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zHFJ5PD-JukV"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"data.csv\")\n",
        "data.head()\n",
        "data.describe()\n",
        "print(data.shape)\n",
        "data.isnull().sum()\n",
        "data.isnull().sum().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "icPvTJX_KD-R",
        "outputId": "d6146b7e-8855-422a-9b0f-d366f97cf3ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(569, 33)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "569"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# last colum is all null so remove it\n",
        "data.drop(data.columns[[32]],axis=1,inplace=True)\n",
        "data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7BNla6JROWZN",
        "outputId": "e57cdee3-5351-4e08-e5c3-0696b38a5876"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(569, 32)"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.diagnosis.value_counts().plot(kind=\"bar\", width=0.1, color=[\"lightgreen\", \"cornflowerblue\"], legend=1, figsize=(8, 5))\n",
        "plt.xlabel(\"(0 = Benign) (1 = Malignant)\", fontsize=12)\n",
        "plt.ylabel(\"Count\", fontsize=12)\n",
        "plt.xticks(fontsize=12);\n",
        "plt.yticks(fontsize=12)\n",
        "plt.legend([\"Benign\"], fontsize=12)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "JakhXKawltjd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['diagnosis'].unique()\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "encoder = LabelEncoder()\n",
        "y = encoder.fit_transform(data['diagnosis'])\n",
        "y = pd.Series(y)\n",
        "X = data.drop(data.columns[[0,1]],axis=1,inplace=False)\n",
        "print(type(y))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "haoIg8dsYAob",
        "outputId": "f22c5882-bbc0-458f-f412-9619de1de932"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.series.Series'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(20, 8))\n",
        "data_new = pd.concat([y,X],axis=1)\n",
        "data_new.rename(columns = {0:\"TARGET\"},inplace=True)\n",
        "data_new.drop('TARGET', axis=1).corrwith(data_new.TARGET).plot(kind='bar', grid=True, title=\"Correlation of Squared Error Features with TARGET\", color=\"blue\")"
      ],
      "metadata": {
        "id": "nREckwL7_07V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=1)\n",
        "print(\"X_train_0.shape, y_train.shape\", X_train.shape, y_train.shape)\n",
        "print(\"X_test_0.shape, y_test.shape\", X_test.shape, y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tLs928JpmfdN",
        "outputId": "d00c7d25-b4af-4c2b-99e3-c0f2bb674384"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train_0.shape, y_train.shape (455, 30) (455,)\n",
            "X_test_0.shape, y_test.shape (114, 30) (114,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Feature reduction**\n",
        "\n",
        "There are various popular methods for feature reduction; the feature selection technique demonstrated here comprises two methods applied in sequence:\n",
        "\n",
        "\n",
        "\n",
        "1.   Univariate feature reduction (remove low correlations with the target).\n",
        "2.   Feature reduction based on collinearity (for each highly correlated pair, use only the feature that correlates better with the target value).\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "dB9UxAv6nkjH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def corr_matrix(y,X, isPlot):\n",
        "  yX = pd.concat([y, X], axis=1)\n",
        "  yX = yX.rename(columns = {0: 'TARGET'})\n",
        "  yX_corr = yX.corr(method = 'pearson').round(2)\n",
        "  #abs(corr_mat.TARGET).nlargest(2)\n",
        "  yX_abs_corr = np.abs(yX_corr)\n",
        "  if isPlot:\n",
        "    #plt.figure(figsize=(10,10))\n",
        "    #sns.heatmap(data = yX_abs_corr,annot=True)\n",
        "    #plt.show()\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    plt.imshow(yX_abs_corr, cmap='RdYlGn', interpolation='none', aspect='auto')\n",
        "    plt.colorbar()\n",
        "    plt.xticks(range(len(yX_abs_corr)), yX_abs_corr.columns, rotation='vertical')\n",
        "    plt.yticks(range(len(yX_abs_corr)), yX_abs_corr.columns);\n",
        "    plt.suptitle('Pearson Correlation Heat Map (absolute values)', fontsize=15, fontweight='bold')\n",
        "    plt.show()\n",
        "  return yX, yX_corr, yX_abs_corr\n",
        "\n",
        "yX, yX_corr, yX_abs_corr = corr_matrix(y_train,X_train,isPlot=True)"
      ],
      "metadata": {
        "id": "S260owbYnj83"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1 Univariate feature reduction (remove low correlations with the target)"
      ],
      "metadata": {
        "id": "eQF4gbI4zQN7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#print(np.abs(yX_abs_corr.TARGET).nlargest(3))\n",
        "sort_corr_y = yX_abs_corr['TARGET'].sort_values(ascending=False)\n",
        "sort_corr_y[sort_corr_y<=0.1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wFjBVJi_zPPs",
        "outputId": "88130387-f6b8-4c82-9358-ab2da9425efb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "fractal_dimension_se      0.07\n",
              "smoothness_se             0.07\n",
              "fractal_dimension_mean    0.04\n",
              "texture_se                0.02\n",
              "symmetry_se               0.02\n",
              "Name: TARGET, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 188
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Find features that have a low correlation with Target Variable and remove them"
      ],
      "metadata": {
        "id": "xyguXlva3GPa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "xy = pd.concat([y_train,X_train],axis=1)\n",
        "corr_xy = xy.corr(method='pearson').abs()\n",
        "corr_xy = corr_xy.rename(columns = {0:\"TARGET\"},index={0:\"TARGET\"})\n",
        "corr_target = corr_xy['TARGET'].abs()\n",
        "corr_target.sort_values(ascending=False,inplace=True)\n",
        "# remove those feature that has correlation less than 0.1 with target (y) variable\n",
        "to_drop_target  = corr_target[corr_target < 0.1]\n",
        "#print(corr_target)\n",
        "\n",
        "remain_cols = list(set(X_train.columns)-set(to_drop_target.index))\n",
        "print(len(remain_cols))\n",
        "\n",
        "#remove these features from X_train data\n",
        "print(X_train.shape)\n",
        "X_train_new = X_train[remain_cols]\n",
        "print(X_train_new.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P3WYwe5Xej7d",
        "outputId": "d231bfe6-2536-4df9-d65d-6dbbda35ee76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25\n",
            "(455, 30)\n",
            "(455, 25)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# now we create corr for X_train_new and Y and remove those columns which are highly correlated\n",
        "df_xy = pd.concat([y_train, X_train_new],axis=1)\n",
        "df_xy.rename(columns = {0:\"TARGET\"},index={0:\"TARGET\"},inplace=True)\n",
        "corr_matrix = X_train_new.corr().abs()\n",
        "print(X_train_new.shape)\n",
        "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
        "to_drop_corr = [column for column in upper.columns if any(upper[column] > 0.9)]\n",
        "X_train_2 = X_train_new.drop(to_drop_corr, axis=1, inplace=False)\n",
        "print(X_train_2.shape)\n",
        "\n",
        "X_test_temp = X_test[remain_cols]\n",
        "X_test_2 = X_test_temp.drop(to_drop_corr,axis=1,inplace=False)\n",
        "print(X_test_2.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3LSSif959zaX",
        "outputId": "f488b5c9-792f-4c06-b46e-59c95948cdc4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(455, 25)\n",
            "(455, 15)\n",
            "(114, 15)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corr_x = X.corr(method='pearson').abs()\n",
        "upper_tri = corr_x.where(np.triu(np.ones(corr_x.shape),k=1).astype(np.bool))\n",
        "# drop columns with high correlation > 0.95\n",
        "to_drop = [cl for cl in upper_tri.columns if any(upper_tri[cl]>.95)]\n",
        "#print(to_drop)\n",
        "#---------------------------------------\n",
        "drops = list(to_drop_target.index) + to_drop\n",
        "X_new_cor = X.drop(drops,axis=1)\n",
        "print(X_new_cor.shape)\n",
        "print(X_new_cor.columns)"
      ],
      "metadata": {
        "id": "B34ZOvtW3gUo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_selection import SelectKBest,chi2, f_regression,f_classif\n",
        "fs_chi = SelectKBest(score_func=chi2,k='all')\n",
        "fit_chi2 = fs_chi.fit(X_train,y_train)\n",
        "p_values = pd.DataFrame(fit_chi2.pvalues_)\n",
        "scores = pd.DataFrame(fit_chi2.scores_)\n",
        "input_variable_names = pd.DataFrame(X_train.columns)\n",
        "summary_stats = pd.concat([input_variable_names, p_values, scores], axis = 1)\n",
        "summary_stats.columns = [\"input_variable\", \"p_value\", \"chi2_score\"]\n",
        "summary_stats.sort_values(by = \"p_value\", inplace = True)\n",
        "p_value_threshold = 0.05\n",
        "score_threshold = 5\n",
        "selected_variables = summary_stats.loc[(summary_stats[\"chi2_score\"] >= score_threshold) & (summary_stats[\"p_value\"] <= p_value_threshold)]\n",
        "selected_variables = selected_variables[\"input_variable\"].tolist()\n",
        "print(len(selected_variables))\n",
        "X_new_chi = X_train[selected_variables]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BsufsjnMzjW4",
        "outputId": "2ae6de3d-4e6d-4cb3-d1da-21370d2b56df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "17\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fs_classif = SelectKBest(score_func=f_classif,k='all')\n",
        "fit_classif = fs_classif.fit(X_train,y_train)\n",
        "cl_pVals = pd.DataFrame(fit_classif.pvalues_)\n",
        "cl_scores =pd.DataFrame(fit_classif.scores_)\n",
        "summary_stat_2 = pd.concat([input_variable_names,cl_pVals,cl_scores],axis=1)\n",
        "summary_stat_2.columns = [\"input_variables\",\"p_value\",\"classif_score\"]\n",
        "print(summary_stat_2)\n",
        "#**************************************\n",
        "summary_stat_2.sort_values(by=\"p_value\",inplace=True)\n",
        "selected_variables_2 = summary_stat_2.loc[(summary_stat_2[\"classif_score\"] >= score_threshold) &\n",
        "                                       (summary_stat_2[\"p_value\"] <= p_value_threshold)]\n",
        "selected_variables_2 = selected_variables_2[\"input_variables\"].tolist()\n",
        "print(len(selected_variables_2))\n",
        "X_new_classif = X_train[selected_variables_2]\n"
      ],
      "metadata": {
        "id": "43TKK3jaKZNu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(X_new_chi.columns))\n",
        "print(X_new_chi.shape)\n",
        "\n",
        "print(len(X_new_classif.columns))\n",
        "print(X_new_classif.shape)\n",
        "\n",
        "print(len(X_new_cor.columns))\n",
        "\n",
        "# we use the X_new_cor\n",
        "print(X_new_cor.shape)"
      ],
      "metadata": {
        "id": "GTmVek9ENlPe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feature Scaling"
      ],
      "metadata": {
        "id": "ke2DX_-OxYz-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "X_train = scaler.fit_transform(X_train_2)\n",
        "X_test = scaler.fit_transform(X_test_2)"
      ],
      "metadata": {
        "id": "aLDh55m8m-HN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import confusion_matrix,accuracy_score\n",
        "trainning_accuracy = []\n",
        "test_accuracy = []\n",
        "\n",
        "for k in range(1,15):\n",
        "  knn = KNeighborsClassifier(n_neighbors=k)\n",
        "  knn.fit(X_train_2,y_train)\n",
        "  trainning_accuracy.append(knn.score(X_train_2,y_train))\n",
        "  test_accuracy.append(knn.score(X_test_2,y_test))\n",
        "  #*************************************\n",
        "\n",
        "plt.plot(range(1,15),trainning_accuracy,label = \"Tranining Accuracy\")\n",
        "plt.plot(range(1,15),test_accuracy,label = \"Testing Accuracy\")\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Number of Neighbers')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "classifier = KNeighborsClassifier(n_neighbors=6)\n",
        "classifier.fit(X_train_2,y_train)\n",
        "y_pred = (classifier.predict(X_test_2))\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(accuracy_score(y_test, y_pred))\n",
        "\n"
      ],
      "metadata": {
        "id": "gdbUgFnZW4KG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# logistic regression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "lg = LogisticRegression(random_state=0)\n",
        "lg.fit(X_train_2,y_train)\n",
        "print('Accuracy on the training set: {:.3f}'.format(lg.score(X_train_2,y_train)))\n",
        "print('Accuracy on the training set: {:.3f}'.format(lg.score(X_test_2,y_test)))\n",
        "\n",
        "y_pred = lg.predict(X_test_2)\n",
        "from sklearn.metrics import accuracy_score,confusion_matrix,precision_recall_curve\n",
        "print(\"---------------\")\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(cm)\n",
        "print(accuracy_score(y_test, y_pred))\n"
      ],
      "metadata": {
        "id": "40BL2qka1lVw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# decision tree\n",
        "from sklearn.tree import DecisionTreeClassifier,export_graphviz\n",
        "train_accuracy = []\n",
        "test_accuracy = []\n",
        "for i in range(1,15):\n",
        "  dt = DecisionTreeClassifier(max_depth = i,random_state=0)\n",
        "  dt.fit(X_train_2,y_train)\n",
        "  train_accuracy.append(dt.score(X_train_2,y_train))\n",
        "  test_accuracy.append(dt.score(X_test_2,y_test))\n",
        "\n",
        "plt.plot(range(1,15),train_accuracy,label = \"training accuracy\")\n",
        "plt.plot(range(1,15),test_accuracy,label= \"testing accuracy \")\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Max Depth')\n",
        "plt.legend()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "saoxDU2T-1wz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "export_graphviz(dt, out_file='cancerTree.dot', class_names=['malignant','benign'], feature_names=X_train_2.columns, impurity=False, filled=True)\n",
        "print('Feature importances: {}'.format(dt.feature_importances_))\n",
        "type(dt.feature_importances_)\n",
        "\n",
        "#Feature Importance\n",
        "n_feature = X_train_2.shape[1]\n",
        "plt.barh(range(n_feature), dt.feature_importances_, align='center')\n",
        "plt.yticks(np.arange(n_feature), X_train_2.columns)\n",
        "plt.xlabel('Feature Importance')\n",
        "plt.ylabel('Feature')\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "F1rTrthvBPpg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Random Forest\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "rf = RandomForestClassifier(n_estimators=100, criterion='entropy',random_state=0)\n",
        "rf.fit(X_train_2,y_train)\n",
        "print('acc for training data: {:.3f}'.format(rf.score(X_train_2,y_train)))\n",
        "print('acc for test data: {:.3f}'.format(rf.score(X_test_2,y_test)))\n",
        "\n",
        "y_pred = rf.predict(X_test_2)\n",
        "cm_rf = confusion_matrix(y_test,y_pred)\n",
        "print(cm_rf)\n",
        "print(accuracy_score(y_test, y_pred))\n",
        "\n",
        "#Feature Importance\n",
        "n_feature =X_train_2.shape[1]\n",
        "plt.barh(range(n_feature), rf.feature_importances_, align='center')\n",
        "plt.yticks(np.arange(n_feature), X_train_2.columns)\n",
        "plt.xlabel('Feature Importance')\n",
        "plt.ylabel('Feature')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "WyRdlkpIHbHo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "svm = SVC()\n",
        "svm.fit(X_train_2,y_train)\n",
        "print(\"training score\", svm.score(X_train_2,y_train))\n",
        "print(\"testing score\", svm.score(X_test_2,y_test))\n",
        "y_pred = svm.predict(X_test_2)\n",
        "print(\"-----------------------------\")\n",
        "print(accuracy_score(y_pred,y_test))\n",
        "confusion_matrix(y_pred, y_test)\n",
        "\n",
        "plt.plot(X_train_2.min(axis=0), 'o', label='Min')\n",
        "plt.plot(X_train_2.max(axis=0), 'v', label='Max')\n",
        "plt.xlabel('Feature Index')\n",
        "plt.ylabel('Feature Magnitude in Log Scale')\n",
        "plt.yscale('log')\n",
        "plt.legend(loc='upper right')"
      ],
      "metadata": {
        "id": "yCTGJI1KN0it"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}